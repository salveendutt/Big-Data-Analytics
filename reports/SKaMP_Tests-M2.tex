\documentclass[12pt,a4paper, hidelinks]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{a4paper, margin=1in}
\usepackage{fancyhdr}
\usepackage{indentfirst} % Add this line to enable first paragraph indentation
\usepackage{times} % Use Times New Roman font
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{float}
\usepackage{listings}

\setstretch{1.15} % Adjust the stretch factor as needed

\pagestyle{fancy}
\fancyhf{}  % Clear header and footer fields
\rfoot{\thepage}  % Place page number at the right bottom corner
\renewcommand{\headrulewidth}{0pt}  % Remove the header line


\begin{document}

\section*{SKaMP. Tests}
\addcontentsline{toc}{section}{Introduction}
\vspace{\baselineskip} % Add an empty line after the section title

The goal of this report is to provide information on the performed testing of data acquisition and data pre-processing.

GitHub repository: \href{https://github.com/salveendutt/Big-Data-Analytics}{https://github.com/salveendutt/Big-Data-Analytics}.

\section{Data acquisition}

\begin{table}[htbp]
\centering
\begin{tabular}{|p{3cm}|p{4cm}|p{3cm}|p{5cm}|}
\hline
\textbf{Test objective} & \textbf{Steps} & \textbf{Expected Result} & \textbf{Actual Result} \\
\hline
Verify data incoming from stream API & 1. Start the server using start\_containers.bat; 2. Navigate to http://localhost:5000 & Incoming data is available on /data/0 & Passed. The screenshot is provided in Fig.1 and Fig.2 \\
\hline
Verify correct setup of the stream and data preprocessing functions & Run 'pytest' from the root folder & Data stream is configured as expected; Incoming data is not null; Returned status code - 200. Preprocessing utils return transformed data as expected & Passed. The screenshot is provided in Fig. 8 \\
\hline
Verify correct setup of NiFi, Kafka and Cassandra & Run the containers - follow steps in README.md & Data flows from streamin API to Kafka topics and Cassandra tables & Passed. The screenshot is provided in Fig. 2, 3, 4, 5, 6, 7 \\
\hline
\end{tabular}
\caption{Data acquisition tests}
\end{table}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/test-stream-M2.png}
  \caption{Data incoming via the stream}
  \label{fig:streaming-api}
\end{figure}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\textwidth]{images/m2-kafka-1.png}
  \caption{Kafka Dataset1}
  \label{fig:kafka1}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\textwidth]{images/m2-kafka-2.png}
  \caption{Kafka Dataset2}
  \label{fig:kafka2}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\textwidth]{images/m2-kafka-3.png}
  \caption{Kafka Dataset3}
  \label{fig:kafka3}
\end{figure}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\textwidth]{images/m2-dataset-1.png}
  \caption{Cassandra Dataset1}
  \label{fig:cassandra1}
\end{figure}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\textwidth]{images/m2-dataset-2.png}
  \caption{Cassandra Dataset2}
  \label{fig:cassandra2}
\end{figure}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\textwidth]{images/m2-dataset-3.png}
  \caption{Cassandra Dataset3}
  \label{fig:cassandra3}
\end{figure}

\section{Data pre-processing}

\begin{table}[htbp]
\centering
\begin{tabular}{|p{3cm}|p{2cm}|p{4cm}|p{5cm}|}
\hline
\textbf{Test objective} & \textbf{Steps} & \textbf{Expected Result} & \textbf{Actual Result} \\
\hline
Verify correct data pre-processing of dataset 1 & Run 'pytest' from the root folder & Feature 'type' is correctly transformed into numeric value (5 cases); Feature 'isMerchant' is correctly prepared (2 cases) & PASSED. The screenshot is provided in Fig. 3 \\
\hline
Verify correct data pre-processing of dataset 2 & Run 'pytest' from the root folder & Numeric boolean values are transformed to int from float (4 cases) & PASSED. The screenshot is provided in Fig. 3 \\
\hline
Verify correct data pre-processing of dataset 3 & Run 'pytest' from the root folder & Feature 'entry\_mode' is correctly transformed into numeric value (4 cases); Unnecessary features are omitted. & PASSED. The screenshot is provided in Fig. 3 \\
\hline
Verify correct data pre-processing of dataset 4 & Run 'pytest' from the root folder & Features 'Amount', 'Class' are renamed to 'amount' and 'isFraud'; Extra features are removed & PASSED. The screenshot is provided in Fig. 3 \\
\hline
\end{tabular}
\caption{Data pre-processing tests}
\end{table}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\textwidth]{images/unittests-M2.png}
  \caption{Unit testing result}
  \label{fig:sunset}
\end{figure}

Unit testing is included in the CI/CD pipeline on GitHub and must be successful before any merge into the main branch.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.95\textwidth]{images/github-checks-M2.PNG}
  \caption{GitHub checks before merge}
  \label{fig:sunset}
\end{figure}

\end{document}